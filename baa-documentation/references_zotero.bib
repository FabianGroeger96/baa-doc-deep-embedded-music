
@inproceedings{jean_tile2vec:_2018,
	title = {Tile2Vec: {Unsupervised} representation learning for spatially distributed data},
	shorttitle = {Tile2Vec},
	doi = {10.1609/aaai.v33i01.33013967},
	abstract = {Geospatial analysis lacks methods like the word vector representations and pre-trained networks that significantly boost performance across a wide range of natural language and computer vision tasks. To fill this gap, we introduce Tile2Vec, an unsupervised representation learning algorithm that extends the distributional hypothesis from natural language -- words appearing in similar contexts tend to have similar meanings -- to spatially distributed data. We demonstrate empirically that Tile2Vec learns semantically meaningful representations on three datasets. Our learned representations significantly improve performance in downstream classification tasks and, similar to word vectors, visual analogies can be obtained via simple arithmetic in the latent space.},
	booktitle = {{AAAI}},
	author = {Jean, Neal and Wang, Sherrie and Samar, Anshul and Azzari, George and Lobell, David B. and Ermon, Stefano},
	year = {2018},
	keywords = {Aerial photography, Algorithm, Coherence (physics), Computer vision, Distributional semantics, Downstream (software development), Feature extraction, Feature learning, File spanning, Geospatial analysis, Image resolution, Information, Machine learning, Natural language, Seasonality, Sensor, Supervised learning, Unsupervised learning, Word embedding}
}

@article{jean_tile2vec:_2019,
	title = {Tile2Vec: {Unsupervised} {Representation} {Learning} for {Spatially} {Distributed} {Data}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Tile2Vec},
	url = {https://www.aaai.org/ojs/index.php/AAAI/article/view/4288},
	doi = {10.1609/aaai.v33i01.33013967},
	abstract = {Geospatial analysis lacks methods like the word vector representations and pre-trained networks that significantly boost performance across a wide range of natural language and computer vision tasks. To fill this gap, we introduce Tile2Vec, an unsupervised representation learning algorithm that extends the distributional hypothesis from natural language — words appearing in similar contexts tend to have similar meanings — to spatially distributed data. We demonstrate empirically that Tile2Vec learns semantically meaningful representations for both image and non-image datasets. Our learned representations significantly improve performance in downstream classification tasks and, similarly to word vectors, allow visual analogies to be obtained via simple arithmetic in the latent space.},
	language = {en},
	number = {01},
	urldate = {2020-02-10},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Jean, Neal and Wang, Sherrie and Samar, Anshul and Azzari, George and Lobell, David and Ermon, Stefano},
	month = jul,
	year = {2019},
	pages = {3967--3974}
}

@misc{noauthor_tile2vec:_nodate,
	title = {Tile2Vec: {Unsupervised} representation learning for spatially distributed data},
	url = {https://ermongroup.github.io/blog/tile2vec/},
	urldate = {2020-02-10}
}

@article{jean_tile2vec:_2018-1,
	title = {Tile2Vec: {Unsupervised} representation learning for spatially distributed data},
	shorttitle = {Tile2Vec},
	url = {http://arxiv.org/abs/1805.02855},
	abstract = {Geospatial analysis lacks methods like the word vector representations and pre-trained networks that significantly boost performance across a wide range of natural language and computer vision tasks. To fill this gap, we introduce Tile2Vec, an unsupervised representation learning algorithm that extends the distributional hypothesis from natural language -- words appearing in similar contexts tend to have similar meanings -- to spatially distributed data. We demonstrate empirically that Tile2Vec learns semantically meaningful representations on three datasets. Our learned representations significantly improve performance in downstream classification tasks and, similar to word vectors, visual analogies can be obtained via simple arithmetic in the latent space.},
	urldate = {2020-02-10},
	journal = {arXiv:1805.02855 [cs, stat]},
	author = {Jean, Neal and Wang, Sherrie and Samar, Anshul and Azzari, George and Lobell, David and Ermon, Stefano},
	month = may,
	year = {2018},
	note = {arXiv: 1805.02855},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_vincent_nodate,
	title = {Vincent {Spruyt}: {Loc}2Vec: {Self}-supervised metric learning through triplet-loss},
	shorttitle = {Vincent {Spruyt}},
	url = {https://www.youtube.com/watch?v=SUM670TPTQ0},
	abstract = {Self-supervised learning is an increasingly popular technique to learn meaningful representations of data when no labels are available. A related problem is that of learning a mapping from raw input data into a metric space, where distances between latent data points are proportional to the semantic similarity between the original data instances. In this talk, we show how triplet-loss can be used to train a neural network in a self-supervised manner by applying it to location data. The result is a transformation from raw latitude/longitude coordinates to an embedding vector with similar properties as word2vec exhibits for natural language.

Bio: Vincent serves as Chief AI Officer at Sentiance, a scale-up that uses AI to model, predict and coach human behaviour using smartphone sensor data. Previously, he acted as Chief Scientist and Vice President of Sentiance since joining in June 2014, during which he was responsible for building out the machine learning team at Sentiance, applying state-of-the-art academic research to real-life problems. Vincent holds a PhD in machine learning and was awarded the MIT innovators under 35 award in 2017. He founded several startups in his past and has years of experience in both the technology industry and the world of academic research. Being the driving force behind the Ethical AI task force within Sentiance, he is deeply involved in the process of providing tooling and education to ensure algorithmic fairness across the Sentiance platform.

*Sponsors*
Man AHL: At Man AHL, we mix machine learning, computer science and engineering with terabytes of data to invest billions of dollars every day.

Evolution AI: Machines that Read - get answers from your text data.},
	urldate = {2020-02-10}
}

@misc{rangarajulu_loc2vec_2019,
	title = {Loc2vec — a fast pytorch implementation},
	url = {https://medium.com/@sureshr/loc2vec-a-fast-pytorch-implementation-2b298072e1a7},
	abstract = {{\textasciitilde}60x faster implementation due to newer techniques and shortcuts},
	language = {en},
	urldate = {2020-02-10},
	journal = {Medium},
	author = {Rangarajulu, Suresh},
	month = mar,
	year = {2019}
}

@misc{das_image_2019,
	title = {Image similarity using {Triplet} {Loss}},
	url = {https://towardsdatascience.com/image-similarity-using-triplet-loss-3744c0f67973},
	abstract = {Have you ever trained a Machine Learning model to solve a classification problem? If yes, what was the number of classes? maybe 10 to 200…},
	language = {en},
	urldate = {2020-02-10},
	journal = {Medium},
	author = {Das, Shibsankar},
	month = jul,
	year = {2019}
}

@article{balntas_pn-net:_2016,
	title = {{PN}-{Net}: {Conjoined} {Triple} {Deep} {Network} for {Learning} {Local} {Image} {Descriptors}},
	shorttitle = {{PN}-{Net}},
	url = {http://arxiv.org/abs/1601.05030},
	abstract = {In this paper we propose a new approach for learning local descriptors for matching image patches. It has recently been demonstrated that descriptors based on convolutional neural networks (CNN) can significantly improve the matching performance. Unfortunately their computational complexity is prohibitive for any practical application. We address this problem and propose a CNN based descriptor with improved matching performance, significantly reduced training and execution time, as well as low dimensionality. We propose to train the network with triplets of patches that include a positive and negative pairs. To that end we introduce a new loss function that exploits the relations within the triplets. We compare our approach to recently introduced MatchNet and DeepCompare and demonstrate the advantages of our descriptor in terms of performance, memory footprint and speed i.e. when run in GPU, the extraction time of our 128 dimensional feature is comparable to the fastest available binary descriptors such as BRIEF and ORB.},
	urldate = {2020-02-10},
	journal = {arXiv:1601.05030 [cs]},
	author = {Balntas, Vassileios and Johns, Edward and Tang, Lilian and Mikolajczyk, Krystian},
	month = jan,
	year = {2016},
	note = {arXiv: 1601.05030},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{schroff_facenet:_2015,
	title = {{FaceNet}: {A} {Unified} {Embedding} for {Face} {Recognition} and {Clustering}},
	shorttitle = {{FaceNet}},
	url = {http://arxiv.org/abs/1503.03832},
	doi = {10.1109/CVPR.2015.7298682},
	abstract = {Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63\%. On YouTube Faces DB it achieves 95.12\%. Our system cuts the error rate in comparison to the best published result by 30\% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.},
	urldate = {2020-02-10},
	journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
	month = jun,
	year = {2015},
	note = {arXiv: 1503.03832},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {815--823}
}

@article{hoffer_deep_2018,
	title = {Deep metric learning using {Triplet} network},
	url = {http://arxiv.org/abs/1412.6622},
	abstract = {Deep learning has proven itself as a successful set of models for learning useful semantic representations of data. These, however, are mostly implicitly learned as part of a classification task. In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons. A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval. Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network. We also discuss future possible usage as a framework for unsupervised learning.},
	urldate = {2020-02-10},
	journal = {arXiv:1412.6622 [cs, stat]},
	author = {Hoffer, Elad and Ailon, Nir},
	month = dec,
	year = {2018},
	note = {arXiv: 1412.6622},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_loc2vec:_2018,
	title = {Loc2Vec: {Learning} location embeddings with triplet-loss networks},
	shorttitle = {Loc2Vec},
	url = {https://www.sentiance.com/2018/05/03/venue-mapping/},
	abstract = {Introduction At Sentiance, we developed a platform that takes in smartphone sensor data such as accelerometer, gyroscope and location information, and extracts behavioral insights. Our AI platform learns about the user’s patterns and is able to predict and explain why and when things happen, allowing our customers to coach their users and engage with them...},
	language = {en-US},
	urldate = {2020-02-10},
	journal = {Sentiance},
	month = may,
	year = {2018}
}

@misc{noauthor_docker_nodate,
	title = {Docker {Hub}},
	url = {https://hub.docker.com/},
	urldate = {2019-12-19}
}

@misc{noauthor_enterprise_nodate,
	title = {Enterprise {Container} {Platform}},
	url = {https://www.docker.com/},
	abstract = {Build, Share, and Run Any App, Anywhere. Learn about the only enterprise-ready container platform to cost-effectively build and manage your application portfolio.},
	language = {en},
	urldate = {2019-12-19},
	journal = {Docker}
}

@misc{noauthor_mt_2019,
	title = {{MT} for {Beginners}: {Was} ist {TER}?},
	shorttitle = {{MT} for {Beginners}},
	url = {https://www.lengoo.de/blog/mt-for-beginners-was-ist-ter/},
	abstract = {Wie funktioniert TER und wo liegen die Limits dieser Metrik? Wir interviewen MT Expertin Svetlana Tchistiakova zum Thema.},
	language = {de},
	urldate = {2019-11-11},
	journal = {lengoo blog},
	month = jan,
	year = {2019}
}

@misc{noauthor_mt_2019-1,
	title = {{MT} for {Beginners}: {Was} ist {BLEU} und wo liegt das {Problem}?},
	shorttitle = {{MT} for {Beginners}},
	url = {https://www.lengoo.de/blog/mt-for-beginners-was-sind-bleu-scores/},
	abstract = {Wir erklären was sich hinter "BLEU Scores" versteckt - und wieso die Frage nach der Korrektheit von Übersetzungen geradezu philosophische Ausmaße annimmt.},
	language = {de},
	urldate = {2019-11-11},
	journal = {lengoo blog},
	month = jan,
	year = {2019}
}

@misc{noauthor_modelle_nodate,
	title = {Modelle bewerten {\textbar} {AutoML} {Translation}-{Dokumentation}},
	url = {https://cloud.google.com/translate/automl/docs/evaluate?hl=de},
	language = {de},
	urldate = {2019-11-11},
	journal = {Google Cloud}
}

@misc{sunnak_evolution_2019,
	title = {Evolution of {Natural} {Language} {Generation}},
	url = {https://medium.com/sfu-big-data/evolution-of-natural-language-generation-c5d7295d6517},
	abstract = {Abhishek Sunnak, Sri Gayatri Rachakonda, Oluwaseyi Talabi},
	language = {en},
	urldate = {2019-10-31},
	journal = {Medium},
	author = {Sunnak, Abhishek},
	month = mar,
	year = {2019}
}

@misc{noauthor_neural_nodate,
	title = {neural style transfer - {Google}-{Suche}},
	url = {https://www.google.com/search?client=safari&rls=en&q=neural+style+transfer&ie=UTF-8&oe=UTF-8},
	urldate = {2019-09-26}
}

@misc{sciforce_comprehensive_2019,
	title = {A {Comprehensive} {Guide} to {Natural} {Language} {Generation}},
	url = {https://medium.com/sciforce/a-comprehensive-guide-to-natural-language-generation-dd63a4b6e548},
	abstract = {As long as Artificial Intelligence helps us to get more out of the natural language, we see more tasks and fields mushrooming at the…},
	language = {en},
	urldate = {2019-09-26},
	journal = {Medium},
	author = {Sciforce},
	month = jul,
	year = {2019}
}

@article{wiseman_challenges_2017,
	title = {Challenges in {Data}-to-{Document} {Generation}},
	url = {http://arxiv.org/abs/1707.08052},
	abstract = {Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difﬁcult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce ﬂuent text, but fail to convincingly approximate humangenerated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy- and reconstructionbased extensions lead to noticeable improvements.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1707.08052 [cs]},
	author = {Wiseman, Sam and Shieber, Stuart M. and Rush, Alexander M.},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.08052},
	keywords = {Computer Science - Computation and Language}
}