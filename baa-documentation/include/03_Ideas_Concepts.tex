\chapter{Ideas and concepts}
\label{ch:Ideas-Concepts}

This chapter explains the different ideas and concepts used in the thesis. Some ideas were discovered during the research and were already introduced in the chapter \fullref{ch:Related-Work}. Others were developed especially for this project and their application, as well as their value, will be proven in this work.
\newline
\newline
It is important to note, that in the thesis two distinct datasets will be used. Due to that, many of the sections in this chapter are divided into two groups, one for the \fullref{sub:DCASE-Task-Dataset} (noise detection) and one for the \fullref{sub:DJ-Dataset} (music detection).

\section{Data preprocessing}
\label{sec:Data-Preprocessing}
Data preprocessing is the process of processing the entire dataset before it is fed into the \fullref{sec:Input-Pipeline}, which will be introduced in the next section. Both datasets used in the project contain audio files for each label. It was decided that data preprocessing was not necessary for this project as the data was already well prepared. Both datasets were used as-is.
\newline
\newline
For the \fullref{sub:DCASE-Task-Dataset}, the data was already preprocessed by the organisers of the challenge. There are no audio files which contain multiple labels, are corrupted or invalid. Because of that, no preprocessing of the data was necessary.
\newline
\newline
For the \fullref{sub:DJ-Dataset}, the data consists of different songs grouped by their respective genre. Because the audios only contain the songs without any background noise in it, the preprocessing was also neglected.

\section{Feature extraction}
\label{sec:Feature-Extraction}
Feature extraction is the process of extracting the relevant features from the raw data; in this case, audio files, which will be done within the \fullref{sec:Input-Pipeline}. For both datasets, the same feature extractions were used. In this project, three different extractions are being evaluated, and are used as a special kind of hyperparameter which can be tuned to achieve the best possible outcome.
\newline
\newline
The first approach is to use the audio files as-is, more precisely to use the raw waveform as input to the model. This is the simplest one and also the most lightweight one to calculate. It is used to evaluate how good a model can be trained without any feature extraction within the audio domain. The approach to use the raw waveform would also be the simplest one to implement in a real-world application, because there is no complex computation needed, and can therefore also be used on small devices, such as mobile phones or Raspberry Pis.
\newline
\newline
The second approach is to calculate the log-mel spectrogram, which is described in subsection \fullref{sub:Mel-Spectrogram} were the last step of calculating the \gls{DCT} is omitted. This approach is widely used in the audio domain because it is less computing extensive than calculating the \gls{MFCC}. It can achieve almost the same scores as a model trained with \gls{MFCC} as their features, because it uses the same computations but preserves more information, by omitting the \gls{DCT}. Thus log-mel spectrograms are the most promising approach for this project.
\newline
\newline
The third approach is to calculate the \gls{MFCC}, which is described in \fullref{sub:Mel-Spectrogram}. This feature extraction method is used mainly in extensive audio applications, such as automatic speech and speaker recognition, where a lot of computing power is available. These features are mostly used because of their nature, that they represent sound like the human auditory system does.
\newline
\newline
All of the features stated above can be thought of as two-dimensional data because of that standard image processing architectures can also be adapted for audio processing.

\section{Data augmentation}
\label{sec:Data-Augmentation}
Data augmentation is the process of changing the real data within the dataset a particular way so that it generates new data. Data augmentation is mainly used to balance imbalanced datasets, where a particular class has significantly less data than others. It can also be used to make the model more invariant to changes in the data so that the model generalises better.
\newline
\newline
Data augmentation will only be used for the \fullref{sub:DCASE-Task-Dataset}, because it is unbalanced in the amount of data each class has, which could correspond to a frequency of the activities in real life. The amount of data in the following six classes: cooking, dishwashing, eating, other, social activity, and vacuum cleaning, is extremely small compared to the other three classes: absence, watching TV and working. Therefore, the amount of audio data for the six classes is increased using data augmentation techniques, proposed in the next paragraph, to mitigate the unbalancing issue.

\section{Triplet selection}
\label{sec:Triplet-Selection}

\section{Input pipeline}
\label{sec:Input-Pipeline}
The input pipeline is responsible for creating the dataset, which will then be fed into the model to train. For this project, the input pipeline is implemented using the Tensorflow \texttt{tf.data} API, along with a generator. A generator function is used because the entire dataset can not be loaded into memory due to the large size of it. Thus the generator generates each batch of the dataset after the other. Among with a specific prefetch value, which will load the next batch of data while the model is training, to utilise the \gls{GPU} fully.
\newline
\newline
Because no preprocessing is being done to the datasets and they are used as-is, the input pipeline will need to do the \fullref{sec:Feature-Extraction}, the \fullref{sec:Data-Augmentation} and as well as the \fullref{sec:Triplet-Selection}.

\section{Models}
\label{sec:Models}

\section{Application to music}
\label{sec:Application-Music}
