\chapter{Conclusion}
\label{ch:Conclusion}
This chapter presents the conclusion of the project, which summarises all of the results from the section evaluation and validation before (\ref{sec:Project-Conclusion}), described the discussion of the thesis in comparison to other research (\ref{sec:Discussion}) and provides useful information about further improvements and an outlook of the thesis (\ref{sec:Outlook}).

\section{Project conclusion}
\label{sec:Project-Conclusion}
This thesis aimed to find an embedding space for both noise detection and music, where the distances in the embedding space represent the similarity between them. The embedding space should be trained using only unsupervised machine learning techniques and therefore should focus on the underlying structure of the audio, rather than its label. To create such an embedding space, Tile2Vec, an image embedding algorithm should be adapted to the audio domain. 
\newline
\newline
Based on the extensive research phase conducted at the start of the project, the concepts, which needed to be used during the thesis, were easily understood. It further provided a lot of insights into the current research in the audio domain more specifically in the unsupervised audio domain. During the research, exciting and useful ideas were found, which then led to the ideas on how to realise this thesis's problem definition. The project plan created at the beginning of the thesis was surprisingly accurate and could be fulfilled almost over the entire project. Further, the chosen linear procedure model, showed many benefits, since, throughout the project, clear deliverables were defined and had to be concluded before moving to the next phase. 
\newline
\newline
Since using TensorFlow 2.0 for the realisation of the thesis, it was surprisingly straightforward to implement state-of-the-art architectures and input pipelines. One of the greatest difficulties during the implementation was that the input pipeline since working with audio data was very slow when using a typical TensorFlow generator pattern, which further resulted in not complete utilisation of the computing resources. A multi-threaded generator had to be implemented from scratch, since TensorFlow does not provide such an implementation by the time of writing, to mitigate that problem. Another difficulty during the realisation was the implementation of the datasets, which included the triplet selection for both datasets, in a matter, that both datasets could be used similarly from the input pipeline and that they can be changed by modifying a single hyperparameter. During the realisation, the advantages of using the test first principle were shown many times. Due to using this principle, many problems, which were related to logical mistakes, could be mitigated and therefore led to better code throughout the entire implementation phase. However, it is to say that it is not always easy to implement useful test cases when working with neural networks since some tests can only be conducted manually.
\newline
\newline
During the experiment phase, the thoughts, which led to the current implementation showed its convenience and practicality, since to conduct a specific experiment only one file, the \texttt{params.json}, had to be changed and it could be started. This led to rapid experiments, however, drained by very long training times. During the vast amount of experiments conducted, many characteristics of the embedding space were shown and were further used to improve the resulting space. The experiments showed, which parameters had the most impact when training an embedding space using an unsupervised triplet loss in the audio domain. For example, it showed, that the larger the segment of the triplets, the better the triplet loss architecture performs, which further leads to a much clearer embedding space.
\newline
\newline
The results from the final embedding space for the \gls{DCASE} challenge dataset showed in comparison to the results of the challenge lower results. However, the results accomplished from the model were using the dataset as unsupervised and by purely focusing on the underlying structure of each audio segment. Thus, the results accomplished are still impressive. Further, it is to say, that these results could easily be higher when using a deeper architecture for the classifier, which is trained using the embedding space as input. However, since the main goal of the thesis was to provide an embedding space, which could represent similarities and dissimilarities between audios, the model showed its true application and advantages. The embedding space of the noise detection dataset succeeded in finding audio files, which were misclassified or contained a microphone malfunction, by purely looking at the neighbourhood of each audio segment. These results are awe-inspiring, because it shows, that a neural network can find structures in audios which sound reasonable, even without the underlying label.
\newline
\newline
The same architecture for training the noise detection embedding space was used to train the embedding space for music. Based on the examination of the embedding space and the qualitative analysis, the results showed even more significant results. It showed that the embedding space succeeded in separating the different sub-genres of the dataset, which is already quite astonishing since these genres are very entangled and the differences are as well for an expert hard to find. This was mainly shown when applying a simple clustering algorithm on the embedded dataset, which resulted in clear clusters of each of the seven categories. Further, the results of a simple classifier trained, using the embedded segment as input, showed, that even when using only a logistic classifier the clusters were easy separable such that an F1 score of approximately 84\% resulted. When examining the embedding space further with the help of an expert, the results showed, that the embedding space found useful similarities in song segments even if they did not correspond to the same sub-genre. The examination further showed that the embedding space was able to create transitions between the sub-genres in the dataset, which were very impressive and sounded interesting.
\newline
\newline
Due to the lack of time and the lack of computing resources, deeper and different neural network architectures were not able to be tested. Deeper state-of-the-art \gls{CNN} architectures should be evaluated as well as state-of-the-art \gls{CRNN} architectures. Further research has to show if using such larger architectures lead to a performance gain or not.
\newline
\newline
Overall the thesis and the results found are considered to be a great success since all of the requirements of the project were able to be satisfied. The embedding space showed even more useful properties than intentionally imagined. The embedding space showed more remarkable performance on the music dataset, even in such entangled sub-genes than on the \gls{DCASE} challenge dataset. However, at the beginning of the project, it was assumed that the results would come out the other way round and the embedding space would perform better on the noise detection dataset than on the music dataset. This was mainly because the use of the music dataset was considered to be a harder challenge.

\section{Discussion}
\label{sec:Discussion}
The results indicate that the embedding space succeeded in finding similarities between audio samples, which was confirmed by the qualitative analysis conducted on the resulting music embedding space. Results from the noise detection embedding space, such as that it found misclassified segments in the dataset, showed that it as well succeeded in finding similarities between the categories in the noise detection dataset. The successful application can be traced back to the differences in the categories of the audio because even in such entangled sub-genres as in the music dataset, there is a difference in the audio, which can be found and used to cluster similarities. These differences can be found, because of the use of triplet loss, which tries to minimise the distance between an anchor and a neighbour segment, while maximising the distance between an anchor and an opposite segment. When adapting this idea to an unsupervised setting and selecting the neighbour segment to belong to the same audio as the anchor and the neighbour to belong to a different audio, the algorithm gets very clear constraints to satisfy. These constraints indicate that the algorithm should project segments of the same song in the near-by region, which was able to be observed when examining both of the embedding spaces.
\newline
\newline
These results build on existing evidence of the distributional hypothesis from natural language, which states that words appearing in similar contexts tend to have similar meanings. The results from this thesis indicate that this hypothesis holds even in the audio domain. Which further indicates, that audio segments, which appear in similar contexts, such as consecutively segments, tend to have similar meanings. However, the results from the qualitative analysis showed that this hypothesis has limitations when looking at an entire song of a specific genre. The hypothesis only holds if enough spectral information is present in the audio, which further indicates that at the start or the end of an audio, certain miss-classifications can happen. Further research is needed to establish if using larger segments would mitigate that difficulty and result in a better performance of the embedding space. 

\section{Outlook}
\label{sec:Outlook}
The results of the thesis showed that it is possible to find similarities between audios of different kinds only by using the audio itself. However, a few flaws in the embedding space were observed, which need to be mitigated in the following research. Such as experiments with larger neural network architectures should be conducted, and see if there is a performance gain in using them. Further, longer audio segments should be used to train the embedding space to see if there is a performance gain. To further improve the performance of the embedding space, the implementation should feature the possibility to specify how many triplets should be generated from each anchor. This would result in a much larger dataset, which leads to a better performing embedding space.
\newline
\newline
This property of finding similarities and dissimilarities can be beneficial for various different applications, such as to find similar songs to the one given or to find similar songs segments to the one provided. It would be even possible to create transitions in between sub-genres, which can be generated by finding the smallest distance between the genres and then using the nearest songs of the distance. The embedding space can further be used to help labels or artists classify their songs by showing them the most similar song to theirs with its corresponding label. 
