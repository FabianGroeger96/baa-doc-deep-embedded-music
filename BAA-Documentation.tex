\documentclass[a4paper]{scrreprt}

%%% PACKAGES %%%

%etoolbox for rules
\usepackage{etoolbox}

% Figure Placement
\usepackage{float}
% PDF/A Compliance
%\usepackage[a-2b,latxmp]{pdfx}

% add Unicode support and use English as language
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

% Use Times NR as font
\usepackage{lmodern}
\usepackage[T1]{fontenc}

% line break for texttt
\usepackage[htt]{hyphenat}

% Better tables
\usepackage{tabularx}
\usepackage[table]{xcolor}
\usepackage{diagbox}
\usepackage{makecell}
\usepackage{longtable}

% Better enumerisation env
\usepackage{enumitem}
\usepackage{multirow}

% Use graphics
\usepackage{graphicx}

% Have subfigures and captions
\usepackage{subcaption}
\usepackage{caption}

% Be able to include PDFs in the file
\usepackage{pdfpages}

% Have custom abstract heading
\usepackage{abstract}

% Need a list of equation
\usepackage{tocloft}
\usepackage{ragged2e}

\usepackage{dirtree}
\usepackage{adjustbox}

% Better equation environment
\usepackage{amsmath}

% Symbols for most SI units
\usepackage{siunitx}

\usepackage{csquotes}

% to make beautiful tables
\usepackage{booktabs}

\DeclareCaptionType{code}[Code Listing][List of Code Listings] 
% to syntax highlighted code samples
\usepackage{minted}
\definecolor{LightGray}{gray}{0.9}
\setminted[python]{
    framesep=2mm,
    baselinestretch=1.2,
    bgcolor=LightGray,
    fontsize=\footnotesize,
    linenos
}
\setminted[bash]{
    framesep=2mm,
    baselinestretch=1.2,
    bgcolor=LightGray,
    fontsize=\footnotesize,
    linenos
}

% Clickable Links to Websites and chapters
\usepackage[hidelinks]{hyperref}

% to have multiple footnotes at the same point in the text
\usepackage[multiple]{footmisc}

% New command for 'fullref'
\newcommand*{\fullref}[1]{\hyperref[{#1}]{\nameref*{#1} (\ref*{#1})}}

% lscape.sty Produce landscape pages in a (mainly) portrait document.
%\usepackage{lscape}
\usepackage{pdflscape}

% Symbols like checkmark
\usepackage{amssymb}
\usepackage{pifont}

% Lorem ipsum package for default text
\usepackage{lipsum}

\usepackage[absolute]{textpos}

% Header
\usepackage{scrlayer-scrpage}

\clearpairofpagestyles

% sets the font of the document headers to Times NR
\addtokomafont{disposition}{\rmfamily}

 % Configures header and footer
\setkomafont{pageheadfoot}{\rmfamily\footnotesize}
\setkomafont{pagehead}{\rmfamily\bfseries}
\setkomafont{pagination}{}

% Displays line for header and footer
\KOMAoptions{
   headsepline = true,
   footsepline = true,
   plainfootsepline = true,
}

\usepackage{pgf-umlcd}

% Tikz to crate diagrams, thanks to: https://github.com/mvoelk/nn_graphics
% Start of tikz settings
\usepackage{tikz}
\usetikzlibrary{positioning,arrows.meta}
\usetikzlibrary{matrix, chains, positioning, decorations.pathreplacing, arrows}
\usetikzlibrary{shapes,arrows,positioning,calc,chains,scopes}

\usepackage{ifthen}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\pgfplotsset{every axis/.append style={tick label style={/pgf/number format/fixed},font=\scriptsize,ylabel near ticks,xlabel near ticks,grid=major}}

\usepackage{amsmath}
\DeclareMathOperator{\sigm}{sigm}
\newcommand{\diff}{\mathop{}\!\mathrm{d}}

% colors
\definecolor{snowymint}{HTML}{E3F8D1}
\definecolor{wepeep}{HTML}{FAD2D2}
\definecolor{portafino}{HTML}{F5EE9D}
\definecolor{plum}{HTML}{DCACEF}
\definecolor{sail}{HTML}{A3CEEE}
\definecolor{highland}{HTML}{6D885A}

\tikzstyle{signal}=[arrows={-latex},draw=black,line width=1pt,rounded corners=4pt]

% RNN
\tikzstyle{block}=[draw=black,line width=1.0pt]
\tikzstyle{cell}=[style=block,draw=highland,fill=snowymint,
    rounded corners]
\tikzstyle{celllayer}=[style=block,draw,fill=portafino,
    inner sep=1pt,outer sep=0,
    minimum width=28pt, minimum height=14pt]
\tikzstyle{pointwise}=[style=block,ellipse,fill=wepeep,
    inner sep=1pt,outer sep=0, minimum size=12pt]

\def\iolen{24pt}
\def\intergape{2pt}

% MLP and CNN
\tikzstyle{netnode}=[circle, inner sep=0pt, text width=22pt, align=center, line width=1.0pt]
\tikzstyle{inputnode}=[netnode, fill=sail, draw=black]
\tikzstyle{hiddennode}=[netnode, fill=snowymint, draw=black]
\tikzstyle{infonode}=[netnode, fill=portafino, draw=black, inner sep=6pt, font=\Large]
\tikzstyle{outputnode}=[netnode, fill=plum, draw=black]

% Architecture
\def\layerwidth{120pt}
\def\layerheight{30pt}

\tikzstyle{layer}=[style=block, draw, fill=black!20!white,
    inner sep=5pt,outer sep=0pt, font=\footnotesize,
    text centered, align=center,
    minimum width=\layerwidth, minimum height=\layerheight]

\tikzstyle{fc}=[style=layer, fill=blue!30!white]
\tikzstyle{conv}=[style=layer, fill=green!30!white]
\tikzstyle{activation}=[style=layer, fill=orange!30!white]
\tikzstyle{pool}=[style=layer, fill=red!30!white]
\tikzstyle{bn}=[style=layer, fill=cyan!30!white]
\tikzstyle{recurrent}=[style=layer, fill=purple!30!white]
\tikzstyle{softmax}=[style=layer, fill=yellow!30!white]
\tikzstyle{point}=[]
\tikzstyle{branch}=[coordinate]

\def\vlayerwidth{30pt}
\def\vlayerheight{3pt}
\def\vblockheight{28pt}

\tikzstyle{vlayer}=[minimum width=\vlayerwidth, minimum height=\vlayerheight]
\tikzstyle{vblock}=[minimum width=\vlayerwidth, minimum height=\vblockheight, text width=1cm, align=center]


% Precision, Recall
\colorlet{fn}{gray!90!green!30!white}
\colorlet{tp}{green!40!white}
\colorlet{fp}{red!40!white}
\colorlet{tn}{gray!90!red!20!white}

% End of tikz settings

\usepackage{pgfgantt}
\usepackage{graphicx}

\ganttset{group/.append style={orange},
milestone/.append style={red},
progress label node anchor/.append style={text=red}}

\automark[chapter]{chapter}

\ohead{\headmark}
\ihead{Fabian Gröger}

\ofoot*{\pagemark}
\ifoot*{HSLU BAA - Deep embedded Music}

% Glossary, hyperref, babel, polyglossia, inputenc, fontenc must be loaded before this package if they are used
\usepackage[ 
xindy,
toc,         
acronym,
nopostdot,
sort=standard   
]{glossaries}

\setglossarystyle{listgroup}

% Define the usage of an acronym, Abbreviation (Abbr.), next usage: The Abbr. of ...
\setacronymstyle{long-short}

% Bibliography & citing
\usepackage[
	backend=biber,
	style=authoryear,
	bibstyle=authoryear,
	citestyle=authoryear
	]{biblatex}
\addbibresource{references.bib}
\DeclareLanguageMapping{english}{english-apa}

%%% COMMAND REBINDINGS %%%
\newcommand{\tabitem}{~~\llap{\textbullet}~~}
\newcommand{\xmark}{\ding{55}}
\newcommand{\notmark}{\textbf{\textasciitilde}}
% Pro/Con item https://tex.stackexchange.com/questions/145198/change-the-bullet-of-each-item#145203
\newcommand\pro{\item[$+$]}
\newcommand\con{\item[$-$]}

% Define list of equations - Thanks to Charles Clayton: https://tex.stackexchange.com/a/354096
\newcommand{\listequationsname}{List of Equations}
\newlistof{myequations}{equ}{\listequationsname}
\newcommand{\myequations}[1]{
	\addcontentsline{equ}{myequations}{\protect\numberline{\theequation}#1}
}
\setlength{\cftmyequationsnumwidth}{2.3em}
\setlength{\cftmyequationsindent}{1.5em}

% Usage {equation}{caption}{label}
\newcommand{\indexequation}[3]{
	\begin{align} \label{#3} \ensuremath{#1} \end{align}
	\myequations{#3} \centering #2 \normalsize \justify }
	
% equations with term definitions, credit to tex.stackexchange.com/questions/95838/how-to-write-a-perfect-equation-parameters-description
\newenvironment{conditions}
  {\par\vspace{\abovedisplayskip}\noindent\begin{tabular}{>{$}l<{$} @{${}={}$} l}}
  {\end{tabular}\par\vspace{\belowdisplayskip}}
  
\newenvironment{conditions*}
  {\par\vspace{\abovedisplayskip}\noindent
   \tabularx{\columnwidth}{>{$}l<{$} @{${}={}$} >{\raggedright\arraybackslash}X}}
  {\endtabularx\par\vspace{\belowdisplayskip}}

% Todolist - credit to https://tex.stackexchange.com/questions/247681/how-to-create-checkbox-todo-list
\newlist{todolist}{itemize}{1}
\setlist[todolist]{label=$\square$}

% Nested Enumeratelist credit to https://tex.stackexchange.com/a/54676
\newlist{legal}{enumerate}{10}
\setlist[legal]{label*=\arabic*.}

% Formatting Chapter title, thanks to: 
% http://texnorte.blogspot.com/2012/06/insert-code-before-chapter-title.html
\newcommand\toptitle{}
\makeatletter
\def\@makechapterhead#1{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
    \ifnum \c@secnumdepth >\m@ne
      \if@mainmatter
        \toptitle\par
        \huge\bfseries \@chapapp\space \thechapter
        \par\nobreak
        \vskip 20\p@
      \fi
    \fi
    \interlinepenalty\@M
    \Huge \bfseries #1\par\nobreak
    \vskip 40\p@
  }}
\makeatother

%%% GLOSSARY %%%
\input{acronyms.tex}
\makeglossaries

%%% PATH DEFINITIONS %%%
% Define the path were images are found
\graphicspath{{./img/}{./study-doc/}}

% Reset Glossary every chapter
\preto\chapter{\glsresetall}

%%%%%%%%%%%%%%%%
%%% DOCUMENT %%%

\begin{document}

% HSLU Preamble (no header or footer)
\pagestyle{empty}

% Cover Page
\include{include/00_Cover_Page}
\include{include/00_HSLU_Preamble}

% Rest of the document has header and footer
\pagestyle{headings}
\pagenumbering{Roman}

% Abstract
\begin{abstract}
    Für den Menschen ist die Unterscheidung zwischen Musikgattungen von einfach bis schwierig, je nachdem, wie ähnlich sich die jeweiligen Genres sind. Es ist ziemlich einfach, zwischen Musikliedern zu unterscheiden, zum Beispiel zwischen klassischer Musik und Techno. Die Schwierigkeit nimmt jedoch zu, wenn Lieder innerhalb desselben Genres verglichen werden. Wenn es darum geht, die Ähnlichkeit zwischen Liedern zu finden oder eine Liste von Liedern nach ihrer Ähnlichkeit zu sortieren, erweist es sich selbst für Menschen als schwierig. In dieser Arbeit wird eine alternative Lernstrategie entwickelt, die sich grundlegende semantische Eigenschaften des Klangs zunutze macht, die nicht durch ein explizites Label gegeben sind. In dieser Arbeit soll Tile2Vec, eine Methode zum Embedden von Bildern, an Audiostreams angepasst und seine Leistungsfähigkeit auf dem \flqq SINS, DCASE 2018: task 5\frqq \ Noise-Detektion-Datensatz sowie auf einem Musikdatensatz, bestehend aus Liedern von sieben Subgenres, evaluiert werden. Tile2Vec ist eine Adaption des Triplet Loss an ein unsupervised Setting unter Verwendung der Verteilungshypothese aus der natürlichen Sprache.

    Der Embedding Space wird durch das Training eines ResNet18-Modells unter Verwendung des Triplet Losses und des log-Mel-Spektrogramms als Input geschaffen. Der dadurch entstehende Embedding Space bildet Ähnlichkeiten zwischen den Datenpunkten ab.
    
    Die ersten Experimente mit dem Noise-Detektion-Datensatz bestätigten, dass der Embedding Space auch ohne Label semantische Eigenschaften lernen kann. Die durchgeführte Fehleranalyse ergab falsch klassifizierte Segmente und Fehlfunktionen der Mikrofone im Datensatz. Darüber hinaus zeigte der Embedding Raum Cluster ähnlich klingender Klänge, unabhängig von seinem Label. Ein einfacher linearer logistischer Klassifikator wird auf den resultierenden Embeddings trainiert, um die Ergebnisse mit denen aus der DCASE-Challenge zu vergleichen. Der beste Klassifikator erreichte einen F1-Score von 62,19\%, während die meisten der im Rahmen des Wettbewerbs eingereichten Modelle Ergebnisse von 80\% und mehr erzielten.
    
    Für den Musikdatensatz wird die gleiche Architektur verwendet, um einen Embedding Space zu trainieren. Er zeigt deutliche Cluster, wenn k-Means auf ihn angewendet wird. Darüber hinaus zeigt jedes Cluster eine signifikant höhere Anzahl von Segmenten einer bestimmten Klasse, was zeigt, dass es dem Modell gelingt, Clusters für jedes Genre zu bilden. Ein Experte bestätigt, dass die Nachbarn jedes Segments, auch wenn sie einer anderen Kategorie angehören, eine Nachbarschaft bilden, die ähnlich klingt. Wenn man den einfachen Klassifikator auf den Musik-Space trainiert, erreicht er einen erstaunlichen F1-Score von ca. 84\% auf ungesehenen Testdaten. Der Experte, der die qualitative Analyse durchführte, war begeistert und beeindruckt von den Ergebnissen.
    
    Zusammenfassend lässt sich sagen, dass die beiden Embedding Spaces unabhängig von ihrem Label erfolgreich gelernt haben, Ähnlichkeiten zu finden, selbst wenn die Kategorien einander sehr ähnlich sind.
\end{abstract}

\begin{abstract}
	For humans to distinguish between music genres is from easy to difficult, depending on how similar the given genres are. It is rather simple to distinguish music songs, for example, of classical music and techno or country and hip-hop rap. However, the difficulty increases if songs within the same genre are compared. When it comes to finding the similarity between songs or to sort a list of songs by their similarity, it is hard, even for humans. In this thesis, an alternative learning strategy is developed that exploits basic semantic properties of sound that are not grounded by an explicit label. This thesis intends to adapt Tile2Vec, an image embedding method, to audio streams and evaluate its performance on the \flqq SINS, DCASE 2018: task 5\frqq \ noise detection dataset as well as on a music dataset, consisting of songs of seven sub-genres. Tile2Vec is an adaption of triplet loss to an unsupervised setting using the distributional hypothesis from natural language, which states that words appearing in similar contexts tend to have similar meanings.
    
    For this work, log Mel spectrograms were used to represent the audios in a more compact form. The selection of triplets is made by using the temporal proximity, and as the network, a state-of-the-art ResNet18 architecture is used. The embedding space is created by training a ResNet18 model utilising the triplet loss and using the log Mel spectrogram as input. This creates a lower-dimensional space, where the distances within, represent the similarities between the data points.
    
    The first experiments with the noise detection dataset confirmed that the embedding space could learn semantic properties even without any label. The conducted error analysis revealed misclassified segments and microphones malfunctions in the dataset. Moreover, the embedding space showed clusters of similar-sounding sounds, regardless of its label. A simple linear logistic classifier trained on the resulting embeddings is compared to the results from the DCASE challenge. The best classifier of this thesis reached an F1 score of 62.19\%, while most of the models submitted to the challenge accomplished results 80\% and higher.
    
    The same architecture is used to train an embedding space for music, which showed similar significant results. It revealed clear clusters when applying k-Means to it. Moreover, each cluster showed a significantly higher amount of segments of a specific class, which demonstrates that the model succeeded in building clusters for each genre. An expert affirmed, that the neighbours of each segment, even if from a different category, build a neighbourhood, which sounds similar and is therefore correct. When training the simple classifier on the music embedding space, it achieved an astonishing F1 score of approximately 84\% on unseen test data. The expert, who performed the qualitative analysis, was thrilled and impressed with the results.
    
    To conclude, the learnt embedding spaces from both datasets successfully learnt to find similarities regardless of its ground truth even if the categories are very similar to each other.
\end{abstract}

% Table of contents
\tableofcontents

\clearpage
\pagenumbering{arabic}

\include{include/01_Introduction}

\include{include/02_Related_Work}

\include{include/03_Ideas_Concepts}

\include{include/04_Method}

\include{include/05_Realisation}

\include{include/06_Evaluation_Validation}

\include{include/07_Conclusion}

\newpage

\pagenumbering{Roman}

\appendix
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}

\listoffigures

\listoftables

\listofmyequations

\listofcodes

\glstocfalse
\printglossary[type=\acronymtype, title=List of Abbreviations]

\printbibliography[heading=bibintoc,title=Bibliography]

\include{include/99_Appendix}

\end{document}
